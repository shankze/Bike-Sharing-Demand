
## Introduction

Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from a one location and return it to a different place on an as-needed basis. Currently, there are over 500 bike-sharing programs around the world.

The data generated by these systems makes them attractive for researchers because the duration of travel, departure location, arrival location, and time elapsed is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants are asked to combine historical usage patterns with weather data in order to forecast bike rental demand in the Capital Bikeshare program in Washington, D.C.


Evaluation:
Submissions are evaluated one the Root Mean Squared Logarithmic Error (RMSLE

### Data

datetime - hourly date + timestamp   
season -  1 = spring, 2 = summer, 3 = fall, 4 = winter   
holiday - whether the day is considered a holiday  
workingday - whether the day is neither a weekend nor holiday  
weather - 1: Clear, Few clouds, Partly cloudy, Partly cloudy   
2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist   
3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds   
4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog   
temp - temperature in Celsius  
atemp - "feels like" temperature in Celsius  
humidity - relative humidity  
windspeed - wind speed  
casual - number of non-registered user rentals initiated  
registered - number of registered user rentals initiated  
count - number of total rentals  

Importing libraries


```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pandas.io.json import json_normalize
import scipy.stats as stats
import pylab
from numpy.random import seed
from numpy.random import randn
from scipy.stats import shapiro
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_log_error
%matplotlib inline
```

Importing datasets


```python
train = pd.read_csv("train.csv")
test = pd.read_csv("test.csv")
```


```python
print(f'Shape of train dataset: {str(train.shape)}')
print(f'Shape of test dataset: {str(test.shape)}')
```

    Shape of train dataset: (10886, 12)
    Shape of test dataset: (6493, 9)
    


```python
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>datetime</th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2011-01-01 00:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2011-01-01 01:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2011-01-01 02:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2011-01-01 03:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2011-01-01 04:00:00</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>




```python
train.describe()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.00000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
      <td>10886.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>2.506614</td>
      <td>0.028569</td>
      <td>0.680875</td>
      <td>1.418427</td>
      <td>20.23086</td>
      <td>23.655084</td>
      <td>61.886460</td>
      <td>12.799395</td>
      <td>36.021955</td>
      <td>155.552177</td>
      <td>191.574132</td>
    </tr>
    <tr>
      <th>std</th>
      <td>1.116174</td>
      <td>0.166599</td>
      <td>0.466159</td>
      <td>0.633839</td>
      <td>7.79159</td>
      <td>8.474601</td>
      <td>19.245033</td>
      <td>8.164537</td>
      <td>49.960477</td>
      <td>151.039033</td>
      <td>181.144454</td>
    </tr>
    <tr>
      <th>min</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.82000</td>
      <td>0.760000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>13.94000</td>
      <td>16.665000</td>
      <td>47.000000</td>
      <td>7.001500</td>
      <td>4.000000</td>
      <td>36.000000</td>
      <td>42.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>3.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>20.50000</td>
      <td>24.240000</td>
      <td>62.000000</td>
      <td>12.998000</td>
      <td>17.000000</td>
      <td>118.000000</td>
      <td>145.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>4.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>2.000000</td>
      <td>26.24000</td>
      <td>31.060000</td>
      <td>77.000000</td>
      <td>16.997900</td>
      <td>49.000000</td>
      <td>222.000000</td>
      <td>284.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
      <td>41.00000</td>
      <td>45.455000</td>
      <td>100.000000</td>
      <td>56.996900</td>
      <td>367.000000</td>
      <td>886.000000</td>
      <td>977.000000</td>
    </tr>
  </tbody>
</table>
</div>




```python
def generateColumnInfo(df):
    cls = []
    nullCount = []
    nonNullCount = []
    nullsPct = []
    uniqCount = []
    dataType = []
    for i,col in enumerate(df.columns):
        cls.append(col)
        nullCount.append(df[col].isnull().sum())
        nonNullCount.append(len(df)-df[col].isnull().sum())
        nullsPct.append((df[col].isnull().sum())*(100)/len(df))
        uniqCount.append(df[col].nunique())
        dataType.append(df[col].dtype)
        
    column_info = pd.DataFrame(
        {'ColumnName': cls,
         'NullCount': nullCount,
         'NonNullCount': nonNullCount,
         'NullPercent': nullsPct,
         'UniqueValueCount': uniqCount,
         'DataType':dataType
        })
    return(column_info)
```


```python
generateColumnInfo(train)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ColumnName</th>
      <th>NullCount</th>
      <th>NonNullCount</th>
      <th>NullPercent</th>
      <th>UniqueValueCount</th>
      <th>DataType</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>datetime</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>10886</td>
      <td>object</td>
    </tr>
    <tr>
      <th>1</th>
      <td>season</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>2</th>
      <td>holiday</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>3</th>
      <td>workingday</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>weather</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>5</th>
      <td>temp</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>49</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>6</th>
      <td>atemp</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>60</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>7</th>
      <td>humidity</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>89</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>8</th>
      <td>windspeed</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>28</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>9</th>
      <td>casual</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>309</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>10</th>
      <td>registered</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>731</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>11</th>
      <td>count</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>822</td>
      <td>int64</td>
    </tr>
  </tbody>
</table>
</div>




```python
generateColumnInfo(test)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ColumnName</th>
      <th>NullCount</th>
      <th>NonNullCount</th>
      <th>NullPercent</th>
      <th>UniqueValueCount</th>
      <th>DataType</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>datetime</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>6493</td>
      <td>object</td>
    </tr>
    <tr>
      <th>1</th>
      <td>season</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>2</th>
      <td>holiday</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>3</th>
      <td>workingday</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>weather</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>5</th>
      <td>temp</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>49</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>6</th>
      <td>atemp</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>65</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>7</th>
      <td>humidity</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>79</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>8</th>
      <td>windspeed</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>27</td>
      <td>float64</td>
    </tr>
  </tbody>
</table>
</div>



Train contains 3 additional columns : casual, registered and count. There are no null values. We will start by converting the text column "datetime" to datetime type. We will extract the date related columns and drop the original column from the train set. We need to retain the datetime column on the test set as it is required to submit the results.


```python
train['date'] = pd.to_datetime(train['datetime'],format='%Y-%m-%d')
train.drop(['datetime'],axis=1,inplace=True)
train['date_year'],train['date_month'],train['date_day'],train['date_weekday'],train['date_hour']  = train['date'].dt.year,train['date'].dt.month,train['date'].dt.day,train['date'].dt.weekday,train['date'].dt.hour
train['weekday_name'] = train['date'].dt.weekday_name

test['date'] = pd.to_datetime(test['datetime'],format='%Y-%m-%d')
test['date_year'],test['date_month'],test['date_day'],test['date_weekday'],test['date_hour']  = test['date'].dt.year,test['date'].dt.month,test['date'].dt.day,test['date'].dt.weekday,test['date'].dt.hour
```


```python
train.head()
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>season</th>
      <th>holiday</th>
      <th>workingday</th>
      <th>weather</th>
      <th>temp</th>
      <th>atemp</th>
      <th>humidity</th>
      <th>windspeed</th>
      <th>casual</th>
      <th>registered</th>
      <th>count</th>
      <th>date</th>
      <th>date_year</th>
      <th>date_month</th>
      <th>date_day</th>
      <th>date_weekday</th>
      <th>date_hour</th>
      <th>weekday_name</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>81</td>
      <td>0.0</td>
      <td>3</td>
      <td>13</td>
      <td>16</td>
      <td>2011-01-01 00:00:00</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>0</td>
      <td>Saturday</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>8</td>
      <td>32</td>
      <td>40</td>
      <td>2011-01-01 01:00:00</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>1</td>
      <td>Saturday</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.02</td>
      <td>13.635</td>
      <td>80</td>
      <td>0.0</td>
      <td>5</td>
      <td>27</td>
      <td>32</td>
      <td>2011-01-01 02:00:00</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>2</td>
      <td>Saturday</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>3</td>
      <td>10</td>
      <td>13</td>
      <td>2011-01-01 03:00:00</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>3</td>
      <td>Saturday</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>9.84</td>
      <td>14.395</td>
      <td>75</td>
      <td>0.0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>2011-01-01 04:00:00</td>
      <td>2011</td>
      <td>1</td>
      <td>1</td>
      <td>5</td>
      <td>4</td>
      <td>Saturday</td>
    </tr>
  </tbody>
</table>
</div>



### Distribution of dependant variable

We see many outliers (3×IQR) in the boxplot.


```python
sns.boxplot(train['count'],orient='v')
```




    <matplotlib.axes._subplots.AxesSubplot at 0xfb0ed9470>




![png](output_17_1.png)



```python
sns.distplot(train['count'])
```




    <matplotlib.axes._subplots.AxesSubplot at 0xfb1219c18>




![png](output_18_1.png)



```python
measurements = np.random.normal(loc = 20, scale = 5, size=100)   
stats.probplot(train['count'], dist="norm", plot=pylab)
pylab.show()
```


![png](output_19_0.png)


The 'count' variable has a right skew. Quantile-Quantile plot shows that it is not showing normal distribution. Shapiro-Wilk's test confirms this behavior.


```python
#Shapiro–Wilk test
stat, p = shapiro(train['count'])
print('p=%.3f' % (p)) #Normal if p>0.1
```

    p=0.000
    

    D:\Anaconda\lib\site-packages\scipy\stats\morestats.py:1310: UserWarning: p-value may not be accurate for N > 5000.
      warnings.warn("p-value may not be accurate for N > 5000.")
    

Log transformation of the dependant variable improves the distribution. I will use the log transformation for statistical modeling.


```python
sns.distplot(np.log1p(train['count']))
```




    <matplotlib.axes._subplots.AxesSubplot at 0xfb155d780>




![png](output_23_1.png)


## Exploratory data analysis (EDA)


```python
#creating additional dataframe for EDA
byUserType = train.drop(['count'],axis=1)
byUserType = pd.melt(byUserType,id_vars = ['season', 'holiday', 'workingday', 'weather', 'temp', 'atemp',
       'humidity', 'windspeed', 'date',
       'date_year', 'date_month', 'date_day', 'date_weekday', 'date_hour',
       'weekday_name'],value_vars = ['casual', 'registered'],var_name='user_type',value_name='user_count')
```

I will analyze each column in this section. I will start with the date/time based columns.

### Date Columns


```python
plt.figure(figsize=(12,7))
sns.boxplot(data=train, x='date_hour',y='count')
plt.title('Average rentals per hour')
plt.xlabel('Hour')
plt.ylabel('Rental count')
plt.show()
```


![png](output_28_0.png)



```python
plt.figure(figsize=(12,7))
sns.barplot(data=train,x='date_hour',y='count',ci=None)
plt.title('Average rentals per hour')
plt.xlabel('Hour')
plt.ylabel('Rental count')
plt.show()
```


![png](output_29_0.png)



```python
plt.figure(figsize=(16,8))
plt.xticks(rotation=90)
ax = sns.barplot(data=byUserType,x='date_hour',y='user_count',hue='user_type',ci=None)
plt.title('Average rentals by hour and user type')
plt.xlabel('Hour')
plt.ylabel('Rental count')
plt.show()
```


![png](output_30_0.png)


Demand is relatively high between 7am-9am and 4pm-7pm. This high demand is fueled by registered users. The demand from casual users is high between 11am-5pm. This could be attributed to the visitors and it coincides with the timings of major tourist attractions in the DC area.


```python
plt.figure(figsize=(12,7))
countByMonth = train.groupby(['date_month'],as_index=False).sum()[['date_month','count']]
ids = countByMonth['date_month']
values = countByMonth['count']
plt.figure(figsize=(12,7))
clrs = ['grey' if (x < 180000) else 'red' for x in values ]
sns.barplot(x=ids,y=values,ci=None,palette=clrs)
plt.title('Average rentals per month')
plt.xlabel('Month')
plt.ylabel('Rental count')
plt.show()
```


    <Figure size 864x504 with 0 Axes>



![png](output_32_1.png)


Demand is high during the summer months (May to October). Both registered and casual riders show the same behavior.


```python
plt.figure(figsize=(12,7))
sns.barplot(data=byUserType,x='date_month',y='user_count',hue='user_type',ci=None)
plt.title('Average user count by month and user type')
plt.xlabel('Month')
plt.ylabel('Rental count')
plt.show()
```


![png](output_34_0.png)



```python
plt.figure(figsize=(12,7))
sns.barplot(data=train,x='weekday_name',y='count',ci=None)
plt.title('Average user count by week day')
plt.xlabel('Day of the week')
plt.ylabel('Rental count')
plt.show()
```


![png](output_35_0.png)



```python
plt.figure(figsize=(12,7))
sns.barplot(data=byUserType,x='weekday_name',y='user_count',hue='user_type',ci=None)
plt.title('Average rentals by day of week and user type')
plt.xlabel('Day of the week')
plt.ylabel('Rental count')
plt.show()
```


![png](output_36_0.png)


* Demand from registered users is higher on weekdays. 
* Demand from casual users is higher on weekends.


```python
plt.figure(figsize=(15,7))
sns.pointplot(data=train,x='date_hour',y='count',hue='weekday_name',ci=None)
plt.title('Rentals by hour and day of the week')
plt.xlabel('Hour')
plt.ylabel('Rental count')
plt.show()
```


![png](output_38_0.png)


* There is a significant difference in the demand between weekdays and weekends.
* On weekdays, the peak demand is during commuting hours (7am-9am) and (4pm-7pm).
* On weekends, the peak demand is betwwen  noon and 4pm.


```python
sns.boxplot(data=train,x='date_year',y='count')
plt.title('Rentals by year')
plt.xlabel('Year')
plt.ylabel('Rental count')
plt.show()
```


![png](output_40_0.png)



```python
sns.boxplot(data=byUserType,x='date_year',y='user_count',hue="user_type")
plt.title('Rentals by year and user type')
plt.xlabel('Year')
plt.ylabel('Rental count')
```




    Text(0,0.5,'Rental count')




![png](output_41_1.png)


### Season


```python
plt.figure(figsize=(8,5))
sns.barplot(data=train,x='season',y='count',ci=None)
ax = plt.axes()
plt.xticks(rotation=0)
ax.set_xticklabels(['spring','summer','fall','winter'])
plt.title('Average demand by season')
plt.xlabel('Season')
plt.ylabel('Rental count')
plt.show()
```

    D:\Anaconda\lib\site-packages\matplotlib\cbook\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.
      warnings.warn(message, mplDeprecation, stacklevel=1)
    


![png](output_43_1.png)



```python
plt.figure(figsize=(15,7))
g = sns.pointplot(data=train,x='date_hour',y='count',hue='season',ci=None)
plt.title('Rentals by hour and season')
plt.xlabel('Hour')
plt.ylabel('Rental count')
plt.show()
```


![png](output_44_0.png)


### Holiday and Working Days


```python
plt.figure(figsize=(8,5))
sns.boxplot(data=byUserType,x='holiday',y='user_count',hue='user_type')
plt.xlabel('Holiday')
plt.ylabel('Rental count')
plt.show()
```


![png](output_46_0.png)



```python
plt.figure(figsize=(8,5))
sns.boxplot(data=byUserType,x='workingday',y='user_count',hue='user_type')
plt.xlabel('Working Day')
plt.ylabel('Rental count')
plt.show()
```


![png](output_47_0.png)


* Demand from registered users is higher during working days
* Demand from casual users is higher during hilidays

### Weather


```python
plt.figure(figsize=(10,5))
sns.barplot(data=train,x='weather',y='count',ci=None)
plt.title('')
ax = plt.axes()
plt.xticks(rotation=0)
ax.set_xticklabels(['Clear','Mist','Light Snow/Rain','Heavy Rain/Thunderstorm'])
plt.title('Rentals by weather')
plt.xlabel('Weather Type')
plt.ylabel('Rental count')
plt.show()
```

    D:\Anaconda\lib\site-packages\matplotlib\cbook\deprecation.py:107: MatplotlibDeprecationWarning: Adding an axes using the same arguments as a previous axes currently reuses the earlier instance.  In a future version, a new instance will always be created and returned.  Meanwhile, this warning can be suppressed, and the future behavior ensured, by passing a unique label to each axes instance.
      warnings.warn(message, mplDeprecation, stacklevel=1)
    


![png](output_50_1.png)


* People prefer to rent bikes during good weather. 
* Interestingly, there is higher demand during Heavy Rains and Thunderstorms than during light rain or snow.

### Temperature


```python
plt.figure(figsize=(10,5))
sns.scatterplot(data=train,x='temp',y='count',ci=None)
plt.title('Rentals vs Temperature')
plt.xlabel('Termerature in degree celsius')
plt.ylabel('Rental count')
plt.show()
```


![png](output_53_0.png)



```python
plt.figure(figsize=(10,5))
sns.scatterplot(data=train,x='humidity',y='count',ci=None)
plt.title('Rental count vs Humidity')
plt.xlabel('Humidity')
plt.ylabel('Rental count')
plt.show()
```


![png](output_54_0.png)



```python
plt.figure(figsize=(10,5))
sns.scatterplot(data=train,x='windspeed',y='count',ci=None)
plt.title('Rental count vs wind speed')
plt.xlabel('Wind speed')
plt.ylabel('Rental count')
plt.show()
```


![png](output_55_0.png)



```python
train.drop(['weekday_name'],inplace=True,axis=1)
```

## Feature Engineering


```python
generateColumnInfo(train)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ColumnName</th>
      <th>NullCount</th>
      <th>NonNullCount</th>
      <th>NullPercent</th>
      <th>UniqueValueCount</th>
      <th>DataType</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>season</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>1</th>
      <td>holiday</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>2</th>
      <td>workingday</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>3</th>
      <td>weather</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>temp</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>49</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>5</th>
      <td>atemp</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>60</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>6</th>
      <td>humidity</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>89</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>7</th>
      <td>windspeed</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>28</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>8</th>
      <td>casual</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>309</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>9</th>
      <td>registered</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>731</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>10</th>
      <td>count</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>822</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>11</th>
      <td>date</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>10886</td>
      <td>datetime64[ns]</td>
    </tr>
    <tr>
      <th>12</th>
      <td>date_year</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>13</th>
      <td>date_month</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>12</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>14</th>
      <td>date_day</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>19</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>15</th>
      <td>date_weekday</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>7</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>16</th>
      <td>date_hour</td>
      <td>0</td>
      <td>10886</td>
      <td>0.0</td>
      <td>24</td>
      <td>int64</td>
    </tr>
  </tbody>
</table>
</div>




```python
generateColumnInfo(test)
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>ColumnName</th>
      <th>NullCount</th>
      <th>NonNullCount</th>
      <th>NullPercent</th>
      <th>UniqueValueCount</th>
      <th>DataType</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>datetime</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>6493</td>
      <td>object</td>
    </tr>
    <tr>
      <th>1</th>
      <td>season</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>2</th>
      <td>holiday</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>3</th>
      <td>workingday</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>4</th>
      <td>weather</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>4</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>5</th>
      <td>temp</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>49</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>6</th>
      <td>atemp</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>65</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>7</th>
      <td>humidity</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>79</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>8</th>
      <td>windspeed</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>27</td>
      <td>float64</td>
    </tr>
    <tr>
      <th>9</th>
      <td>date</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>6493</td>
      <td>datetime64[ns]</td>
    </tr>
    <tr>
      <th>10</th>
      <td>date_year</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>2</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>11</th>
      <td>date_month</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>12</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>12</th>
      <td>date_day</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>12</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>13</th>
      <td>date_weekday</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>7</td>
      <td>int64</td>
    </tr>
    <tr>
      <th>14</th>
      <td>date_hour</td>
      <td>0</td>
      <td>6493</td>
      <td>0.0</td>
      <td>24</td>
      <td>int64</td>
    </tr>
  </tbody>
</table>
</div>




```python
plt.figure(figsize=(15,10))
sns.heatmap(train.corr(),annot=True)
plt.show()
```


![png](output_60_0.png)


* Date_hour shows the highes correlation with count.
* There is a very high co-relation between season and date_month and temp and atemp. 
* I will drop season and atemp columns to avoid multicollinearity.


```python
train.drop(['season','atemp'],inplace=True,axis=1)
test.drop(['season','atemp'],inplace=True,axis=1)
```

One hot encoding "weather"


```python
train = pd.get_dummies(train, columns=['weather'], prefix=['weather_'])
test = pd.get_dummies(test, columns=['weather'], prefix=['weather_'])
```

The date column is no longer required.


```python
train.drop('date',inplace=True,axis=1)
test.drop('date',inplace=True,axis=1)
```


```python
train['date_year'] = train['date_year'].astype("category")
train['date_month'] = train['date_month'].astype("category")
train['date_day'] = train['date_day'].astype("category")
train['date_weekday'] = train['date_weekday'].astype("category")
train['date_hour'] = train['date_hour'].astype("category")
```

## Statistical Modeling


```python
X = train.drop(['count','casual','registered'],axis=1)
y = train['count']
```


```python
X_train,X_valid, y_train,y_valid = train_test_split(X,y, test_size=0.3,random_state=100)
```


```python
res_alg = ['Random Forest','SVR','KNN','GBR','LR']
res_rmsle = []
```


```python
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.neighbors import KNeighborsRegressor
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import GridSearchCV
```


```python
#Random forest
rfModel = RandomForestRegressor()
rfModel.fit(X_train,np.log1p(y_train))
rfPred = rfModel.predict(X_valid)
np.sqrt(mean_squared_log_error(np.exp(rfPred),y_valid))
res_rmsle.append(np.sqrt(mean_squared_log_error(np.exp(rfPred),y_valid)))
```


```python
#Support vector regression
svrModel = SVR()
svrModel.fit(X_train,np.log1p(y_train))
svrPred = svrModel.predict(X_valid)
res_rmsle.append(np.sqrt(mean_squared_log_error(np.exp(svrPred),y_valid)))
```


```python
#K-nearest neighbors
knnModel = KNeighborsRegressor()
knnModel.fit(X_train,np.log1p(y_train))
knnPred = knnModel.predict(X_valid)
res_rmsle.append(mean_squared_log_error(np.exp(knnPred),y_valid))
```


```python
#Gradient boosting regressor
gbModel = GradientBoostingRegressor()
gbModel.fit(X_train,np.log1p(y_train))
gbPred = gbModel.predict(X_valid)
gbPred = pd.DataFrame(gbPred)
gbPred = gbPred[0].apply(lambda x:0.0 if x<0 else x)
res_rmsle.append(np.sqrt(mean_squared_log_error(np.exp(gbPred),y_valid)))
```


```python
#Linear regression
lrModel = LinearRegression()
lrModel.fit(X_train,np.log1p(y_train))
lrPred = lrModel.predict(X_valid)
lrPred = pd.DataFrame(lrPred)
lrPred = lrPred[0].apply(lambda x:0.0 if x<0 else x)
res_rmsle.append(np.sqrt(mean_squared_log_error(np.exp(lrPred),y_valid)))
```


```python
results = pd.DataFrame({'Algorithm':res_alg,'RMSLE':res_rmsle})
results.sort_values('RMSLE')
```




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Algorithm</th>
      <th>RMSLE</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Random Forest</td>
      <td>0.338849</td>
    </tr>
    <tr>
      <th>3</th>
      <td>GBR</td>
      <td>0.405260</td>
    </tr>
    <tr>
      <th>2</th>
      <td>KNN</td>
      <td>0.691466</td>
    </tr>
    <tr>
      <th>1</th>
      <td>SVR</td>
      <td>0.942840</td>
    </tr>
    <tr>
      <th>4</th>
      <td>LR</td>
      <td>1.011953</td>
    </tr>
  </tbody>
</table>
</div>




```python
sns.barplot(data=results,x='Algorithm',y='RMSLE')
```




    <matplotlib.axes._subplots.AxesSubplot at 0xfb2ec5e80>




![png](output_79_1.png)


Random forest gives the lowest RMSLE value. In the next section, I will tune the hyperparameters of the random forest model.

## Tuning

### Random Search

I will define a grid of hyperparameters and use Scikit-Learn’s RandomizedSearchCV method to randomly sample from the grid, performing K-Fold CV with each combination of values. RandomizedSearchCV will not try every combination, but selects at random to sample a wide range of values.K-Fold CV reduces overfitting. I will try adjusting the following set of hyperparameters:

* n_estimators = number of trees in the foreset
* max_features = max number of features considered for splitting a node
* max_depth = max number of levels in each decision tree
* min_samples_split = min number of data points placed in a node before the node is split
* min_samples_leaf = min number of data points allowed in a leaf node
* bootstrap = method for sampling data points (with or without replacement)


```python
n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]
max_features = ['auto', 'sqrt']
max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]
max_depth.append(None)
min_samples_split = [2, 5, 10]
min_samples_leaf = [1, 2, 4]
bootstrap = [True, False]
```


```python
random_grid = {'n_estimators': n_estimators,
               'max_features': max_features,
               'max_depth': max_depth,
               'min_samples_split': min_samples_split,
               'min_samples_leaf': min_samples_leaf,
               'bootstrap': bootstrap}
```


```python
from sklearn.model_selection import RandomizedSearchCV
```


```python
rf = RandomForestRegressor()
rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=1, random_state=42, n_jobs = -1,scoring='neg_mean_squared_log_error')
```


```python
rf_random.fit(X_train,np.log1p(y_train))
```

    Fitting 3 folds for each of 100 candidates, totalling 300 fits
    

    [Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:  1.3min
    [Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  7.1min
    [Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 11.4min finished
    




    RandomizedSearchCV(cv=3, error_score='raise',
              estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,
               max_features='auto', max_leaf_nodes=None,
               min_impurity_decrease=0.0, min_impurity_split=None,
               min_samples_leaf=1, min_samples_split=2,
               min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,
               oob_score=False, random_state=None, verbose=0, warm_start=False),
              fit_params=None, iid=True, n_iter=100, n_jobs=-1,
              param_distributions={'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000], 'max_features': ['auto', 'sqrt'], 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4], 'bootstrap': [True, False]},
              pre_dispatch='2*n_jobs', random_state=42, refit=True,
              return_train_score='warn', scoring='neg_mean_squared_log_error',
              verbose=1)




```python
rf_random.best_params_
```




    {'bootstrap': True,
     'max_depth': 100,
     'max_features': 'auto',
     'min_samples_leaf': 1,
     'min_samples_split': 2,
     'n_estimators': 1400}



### Grid Search CV

Now that we know the range for each hyperparameter, I will fine tune the hyperparameters with GridSearchCV. GridSearchCV will perform KFold Cross validation on each combination. 


```python
param_grid = {
    'bootstrap': [True],
    'max_depth': [100,120,150],
    'max_features': ['auto'],
    'min_samples_leaf': [1,2],
    'min_samples_split': [2,3,4],
    'n_estimators': [500,800,1000 ]
}
```


```python
from sklearn.model_selection import GridSearchCV
```


```python
rf = RandomForestRegressor()
rf_grid = GridSearchCV(estimator =rf,param_grid=param_grid,scoring='neg_mean_squared_log_error',verbose=1,cv=3)
```


```python
rf_grid.fit(X_train,np.log1p(y_train))
pred=rf_grid.predict(X_valid)
```

    Fitting 3 folds for each of 54 candidates, totalling 162 fits
    

    [Parallel(n_jobs=1)]: Done 162 out of 162 | elapsed: 29.6min finished
    


```python
print((np.sqrt(mean_squared_log_error(np.exp(pred),y_valid))))
```

    0.317396652773138
    

Tuning has led to a decrease in the RMSLE value. Let us look at the final hyperparameters:


```python
rf_grid.best_params_
```




    {'bootstrap': True,
     'max_depth': 150,
     'max_features': 'auto',
     'min_samples_leaf': 1,
     'min_samples_split': 3,
     'n_estimators': 800}




```python
f_imp = pd.DataFrame({'Feature':X_train.columns,'Importance':rf_grid.best_estimator_.feature_importances_})
```


```python
plt.figure(figsize=(10,6))
sns.barplot(data=f_imp.sort_values(by='Importance',ascending=False),x='Importance',y='Feature')
plt.title('Feature Importance')
```




    Text(0.5,1,'Feature Importance')




![png](output_100_1.png)


## Generate predictions on Test


```python
testPred=rf_grid.predict(test.drop('datetime',axis=1))
testPred= np.exp(testPred)
d={'datetime':test['datetime'],'count':testPred}
ans=pd.DataFrame(d)
ans.to_csv('answer.csv',index=False)
```
